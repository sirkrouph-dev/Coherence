#!/usr/bin/env python3
"""
Test Suite for GPU Scaling and Large-Scale Network Implementation
================================================================

This test suite validates the GPU scaling capabilities and ensures
large-scale neuromorphic networks can be created and run efficiently
at 100K+ neuron scales.
"""

import pytest
import numpy as np
import time
import traceback
from typing import Dict, List, Any

# Import modules under test
try:
    from core.gpu_scaling import GPUMemoryManager, LargeScaleNetworkBuilder, quick_gpu_scale_test
    from core.gpu_neurons import (
        GPUNeuronPool, 
        AdaptiveGPUNeuronPool, 
        MultiGPUNeuronSystem,
        create_large_scale_gpu_network,
        benchmark_gpu_scaling,
        GPU_AVAILABLE
    )
    IMPORTS_SUCCESS = True
except ImportError as e:
    print(f\"Import error: {e}\")\n    IMPORTS_SUCCESS = False\n\n\nclass TestGPUMemoryManager:\n    \"\"\"Test GPU memory management functionality.\"\"\"\n    \n    def test_memory_manager_initialization(self):\n        \"\"\"Test memory manager can be initialized.\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        manager = GPUMemoryManager()\n        assert manager is not None\n        assert 0.0 <= manager.safety_margin <= 1.0\n        assert manager.gpu_config is not None\n        \n    def test_memory_estimation(self):\n        \"\"\"Test memory requirement estimation.\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        manager = GPUMemoryManager()\n        \n        # Test small network\n        profile_small = manager.estimate_memory_requirements(1000, connectivity=0.05)\n        assert profile_small.total_mb > 0\n        assert profile_small.neurons_mb > 0\n        assert profile_small.synapses_mb > 0\n        \n        # Test large network  \n        profile_large = manager.estimate_memory_requirements(100000, connectivity=0.05)\n        assert profile_large.total_mb > profile_small.total_mb\n        \n    def test_network_optimization(self):\n        \"\"\"Test network configuration optimization.\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        manager = GPUMemoryManager()\n        \n        # Test optimization for reasonable size\n        config = manager.optimize_network_configuration(50000, connectivity=0.05)\n        assert \"num_neurons\" in config\n        assert \"connectivity\" in config\n        assert \"memory_profile\" in config\n        assert config[\"num_neurons\"] > 0\n        \n    def test_memory_monitoring(self):\n        \"\"\"Test memory usage monitoring.\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        manager = GPUMemoryManager()\n        usage = manager.monitor_memory_usage()\n        \n        assert \"used_mb\" in usage\n        assert \"available_mb\" in usage\n        assert \"percent_used\" in usage\n        assert usage[\"used_mb\"] >= 0\n        assert usage[\"percent_used\"] >= 0\n\n\nclass TestLargeScaleNetworkBuilder:\n    \"\"\"Test large-scale network builder.\"\"\"\n    \n    def test_builder_initialization(self):\n        \"\"\"Test builder can be initialized.\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        builder = LargeScaleNetworkBuilder()\n        assert builder is not None\n        assert builder.memory_manager is not None\n        \n    def test_small_network_creation(self):\n        \"\"\"Test creating small networks (should always work).\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        builder = LargeScaleNetworkBuilder()\n        \n        # Create small network that should fit in any system\n        network_data = builder.create_large_scale_network(\n            target_neurons=1000,\n            connectivity=0.05,\n            neuron_type=\"adex\"\n        )\n        \n        assert network_data[\"num_neurons\"] > 0\n        assert network_data[\"connectivity\"] > 0\n        assert \"memory_profile\" in network_data\n        assert \"creation_time\" in network_data\n        \n    def test_large_network_creation(self):\n        \"\"\"Test creating large networks (may trigger optimization).\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        builder = LargeScaleNetworkBuilder()\n        \n        # Try to create large network\n        network_data = builder.create_large_scale_network(\n            target_neurons=50000,\n            connectivity=0.05,\n            neuron_type=\"adex\"\n        )\n        \n        assert network_data[\"num_neurons\"] > 0\n        # Network size might be reduced due to memory constraints\n        assert network_data[\"num_neurons\"] <= 50000\n        \n\nclass TestGPUNeuronPool:\n    \"\"\"Test GPU neuron pool functionality.\"\"\"\n    \n    def test_cpu_fallback(self):\n        \"\"\"Test CPU fallback when GPU unavailable.\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        # Force CPU usage\n        pool = GPUNeuronPool(1000, neuron_type=\"adex\", use_gpu=False)\n        assert pool is not None\n        assert pool.num_neurons == 1000\n        assert pool.device == \"cpu\"\n        \n    @pytest.mark.skipif(not GPU_AVAILABLE, reason=\"GPU not available\")\n    def test_gpu_pool_creation(self):\n        \"\"\"Test GPU neuron pool creation.\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        pool = GPUNeuronPool(5000, neuron_type=\"adex\", use_gpu=True)\n        assert pool is not None\n        assert pool.num_neurons == 5000\n        assert pool.device == \"gpu\"\n        \n    def test_neuron_simulation_step(self):\n        \"\"\"Test neuron simulation step.\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        pool = GPUNeuronPool(1000, neuron_type=\"adex\", use_gpu=GPU_AVAILABLE)\n        \n        # Test simulation step\n        spike_indices, metrics = pool.step(dt=0.1)\n        \n        assert isinstance(spike_indices, np.ndarray) or hasattr(spike_indices, '__array__')\n        assert isinstance(metrics, dict)\n        assert \"compute_time\" in metrics\n        assert \"throughput\" in metrics\n        \n    def test_different_neuron_types(self):\n        \"\"\"Test different neuron types.\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        neuron_types = [\"adex\", \"lif\", \"izhikevich\"]\n        \n        for neuron_type in neuron_types:\n            try:\n                pool = GPUNeuronPool(500, neuron_type=neuron_type, use_gpu=GPU_AVAILABLE)\n                \n                # Test a few steps\n                for _ in range(5):\n                    spike_indices, metrics = pool.step(dt=0.1)\n                    assert metrics[\"compute_time\"] >= 0\n                    \n                # Clean up\n                if hasattr(pool, 'clear_gpu_memory'):\n                    pool.clear_gpu_memory()\n                    \n            except Exception as e:\n                pytest.fail(f\"Failed with neuron type {neuron_type}: {str(e)}\")\n\n\nclass TestAdaptiveGPUNeuronPool:\n    \"\"\"Test adaptive GPU neuron pool.\"\"\"\n    \n    def test_adaptive_pool_creation(self):\n        \"\"\"Test adaptive pool creation with optimization.\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        pool = AdaptiveGPUNeuronPool(10000, neuron_type=\"adex\")\n        assert pool is not None\n        assert hasattr(pool, 'memory_manager')\n        assert hasattr(pool, 'optimization_config')\n        \n    def test_adaptive_step(self):\n        \"\"\"Test adaptive simulation step with monitoring.\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        pool = AdaptiveGPUNeuronPool(5000, neuron_type=\"adex\")\n        \n        # Test adaptive step\n        spike_indices, metrics = pool.adaptive_step(dt=0.1)\n        \n        assert \"memory_usage_mb\" in metrics\n        assert \"memory_percent\" in metrics\n        assert \"optimization_config\" in metrics\n        \n    def test_performance_summary(self):\n        \"\"\"Test performance summary generation.\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        pool = AdaptiveGPUNeuronPool(3000, neuron_type=\"adex\")\n        \n        # Run some steps to generate performance history\n        for _ in range(10):\n            pool.adaptive_step(dt=0.1)\n            \n        summary = pool.get_performance_summary()\n        \n        assert \"total_steps\" in summary\n        assert \"mean_compute_time\" in summary\n        assert \"mean_throughput\" in summary\n        assert summary[\"total_steps\"] == 10\n\n\nclass TestScalingLimits:\n    \"\"\"Test GPU scaling limits and large-scale capabilities.\"\"\"\n    \n    def test_quick_gpu_scale_test(self):\n        \"\"\"Test quick GPU scaling test function.\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        result = quick_gpu_scale_test(target_neurons=10000)\n        assert \"success\" in result\n        \n        if GPU_AVAILABLE:\n            # Should succeed on GPU\n            if not result[\"success\"]:\n                print(f\"GPU test failed: {result}\")\n        else:\n            # May fail without GPU\n            pass\n            \n    def test_create_large_scale_gpu_network(self):\n        \"\"\"Test large-scale network creation function.\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        # Test with moderate size\n        network = create_large_scale_gpu_network(\n            target_neurons=5000,\n            neuron_type=\"adex\",\n            use_adaptive=True\n        )\n        \n        assert network is not None\n        assert hasattr(network, 'num_neurons')\n        assert network.num_neurons > 0\n        \n    @pytest.mark.skipif(not GPU_AVAILABLE, reason=\"GPU required for scaling test\")\n    def test_100k_neuron_network(self):\n        \"\"\"Test creating 100K+ neuron network (GPU required).\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        try:\n            print(\"\\nTesting 100K neuron network creation...\")\n            start_time = time.time()\n            \n            network = create_large_scale_gpu_network(\n                target_neurons=100000,\n                neuron_type=\"adex\",\n                use_adaptive=True\n            )\n            \n            creation_time = time.time() - start_time\n            print(f\"Created {network.num_neurons:,} neurons in {creation_time:.2f}s\")\n            \n            # Test simulation steps\n            step_start = time.time()\n            for i in range(10):\n                if hasattr(network, 'adaptive_step'):\n                    spikes, metrics = network.adaptive_step(0.1)\n                else:\n                    spikes, metrics = network.step(0.1)\n                    \n                if i == 0:  # Print first step metrics\n                    print(f\"First step: {len(spikes) if hasattr(spikes, '__len__') else 'N/A'} spikes, \"\n                          f\"{metrics.get('compute_time', 0):.4f}s compute\")\n                          \n            step_time = time.time() - step_start\n            print(f\"10 simulation steps completed in {step_time:.2f}s\")\n            \n            # Verify network is functional\n            assert network.num_neurons >= 50000  # At least 50K should fit\n            \n            # Clean up\n            if hasattr(network, 'clear_gpu_memory'):\n                network.clear_gpu_memory()\n                \n        except Exception as e:\n            # Print full traceback for debugging\n            print(f\"\\n100K neuron test failed: {str(e)}\")\n            print(traceback.format_exc())\n            pytest.fail(f\"Failed to create/simulate 100K neuron network: {str(e)}\")\n\n\nclass TestMultiGPUSystem:\n    \"\"\"Test multi-GPU system functionality.\"\"\"\n    \n    @pytest.mark.skipif(not GPU_AVAILABLE, reason=\"GPU required for multi-GPU test\")\n    def test_multi_gpu_initialization(self):\n        \"\"\"Test multi-GPU system initialization.\"\"\"\n        if not IMPORTS_SUCCESS:\n            pytest.skip(\"Could not import required modules\")\n            \n        system = MultiGPUNeuronSystem(neuron_type=\"adex\")\n        assert system is not None\n        assert system.num_gpus >= 0\n        \n        if system.num_gpus > 0:\n            print(f\"Multi-GPU system detected {system.num_gpus} GPUs\")\n        else:\n            print(\"No GPUs detected for multi-GPU system\")\n\n\n# Integration test that combines multiple components\ndef test_end_to_end_scaling():\n    \"\"\"End-to-end test of scaling infrastructure.\"\"\"\n    if not IMPORTS_SUCCESS:\n        pytest.skip(\"Could not import required modules\")\n        \n    print(\"\\n=== End-to-End GPU Scaling Test ===\")\n    \n    # 1. Test memory manager\n    manager = GPUMemoryManager()\n    print(f\"GPU Config: {manager.gpu_config.device_name}, \"\n          f\"{manager.gpu_config.total_memory_mb:.0f} MB\")\n    \n    # 2. Test network builder\n    builder = LargeScaleNetworkBuilder(manager)\n    \n    # 3. Create progressively larger networks\n    test_sizes = [1000, 5000, 10000, 25000]\n    \n    for size in test_sizes:\n        print(f\"\\nTesting {size:,} neurons...\")\n        try:\n            network_data = builder.create_large_scale_network(size)\n            print(f\"  \u2713 Created {network_data['num_neurons']:,} neurons\")\n            \n            # Test actual neuron pool creation\n            pool = create_large_scale_gpu_network(network_data['num_neurons'])\n            \n            # Test simulation\n            spikes, metrics = pool.step(0.1)\n            print(f\"  \u2713 Simulation step: {metrics.get('throughput', 0):.0f} neurons/sec\")\n            \n            # Clean up\n            if hasattr(pool, 'clear_gpu_memory'):\n                pool.clear_gpu_memory()\n                \n        except Exception as e:\n            print(f\"  \u2717 Failed: {str(e)}\")\n            # Don't fail the test for larger sizes that may not fit\n            if size <= 5000:\n                raise e\n    \n    print(\"\\nEnd-to-end scaling test completed successfully!\")\n\n\n# Performance benchmark test\ndef test_performance_benchmark():\n    \"\"\"Test performance benchmarking capabilities.\"\"\"\n    if not IMPORTS_SUCCESS:\n        pytest.skip(\"Could not import required modules\")\n        \n    if not GPU_AVAILABLE:\n        pytest.skip(\"GPU required for performance benchmark\")\n        \n    print(\"\\n=== Performance Benchmark Test ===\")\n    \n    try:\n        # Run limited benchmark\n        results = benchmark_gpu_scaling(max_neurons=50000)\n        \n        if 'error' in results:\n            print(f\"Benchmark error: {results['error']}\")\n        else:\n            print(f\"Benchmark completed with results\")\n            \n    except Exception as e:\n        print(f\"Benchmark failed: {str(e)}\")\n        # Don't fail test - benchmarking is optional\n\n\nif __name__ == \"__main__\":\n    # Run tests when executed directly\n    print(\"Running GPU Scaling Tests...\")\n    \n    try:\n        # Run key tests manually\n        print(\"\\n1. Testing GPU Memory Manager...\")\n        manager = GPUMemoryManager()\n        print(f\"   GPU: {manager.gpu_config.device_name}\")\n        print(f\"   Max network: {manager.gpu_config.max_network_size:,} neurons\")\n        \n        print(\"\\n2. Testing Large-Scale Network Creation...\")\n        network = create_large_scale_gpu_network(10000, \"adex\")\n        print(f\"   Created: {network.num_neurons:,} neurons\")\n        \n        print(\"\\n3. Testing Simulation Performance...\")\n        start_time = time.time()\n        spikes, metrics = network.step(0.1)\n        step_time = time.time() - start_time\n        print(f\"   Step time: {step_time:.4f}s\")\n        print(f\"   Throughput: {metrics.get('throughput', 0):.0f} neurons/sec\")\n        \n        print(\"\\n\u2713 All basic tests passed!\")\n        \n        # Clean up\n        if hasattr(network, 'clear_gpu_memory'):\n            network.clear_gpu_memory()\n            \n    except Exception as e:\n        print(f\"\\n\u2717 Test failed: {str(e)}\")\n        traceback.print_exc()\n