{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Encoding and Network Processing Example\n",
    "\n",
    "This notebook demonstrates how to encode images and process them through a spiking neural network.\n",
    "\n",
    "## Overview\n",
    "1. Create or load an image\n",
    "2. Encode it using retinal encoding (ON/OFF channels)\n",
    "3. Convert to spike trains\n",
    "4. Build a visual processing network\n",
    "5. Process the image through the network\n",
    "6. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "\n",
    "from core.encoding import RetinalEncoder, RateEncoder\n",
    "from core.network import NeuromorphicNetwork, NetworkBuilder\n",
    "\n",
    "# Configure matplotlib for inline display\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create a Sample Image\n",
    "\n",
    "We'll create a simple synthetic image with basic patterns for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_image(size=(64, 64)):\n",
    "    \"\"\"Create a sample image with simple patterns.\"\"\"\n",
    "    image = np.zeros(size, dtype=np.uint8)\n",
    "    \n",
    "    # Vertical line\n",
    "    image[:, size[1]//2-2:size[1]//2+2] = 255\n",
    "    \n",
    "    # Horizontal line\n",
    "    image[size[0]//2-2:size[0]//2+2, :] = 255\n",
    "    \n",
    "    # Circle in the center\n",
    "    center = (size[0]//2, size[1]//2)\n",
    "    radius = min(size) // 4\n",
    "    y, x = np.ogrid[:size[0], :size[1]]\n",
    "    mask = (x - center[1])**2 + (y - center[0])**2 <= radius**2\n",
    "    image[mask] = 200\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Create the image\n",
    "image = create_sample_image(size=(64, 64))\n",
    "\n",
    "# Display it\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Sample Input Image')\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Value range: [{image.min()}, {image.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Retinal Encoding\n",
    "\n",
    "Apply retinal encoding to extract ON-center/OFF-surround and OFF-center/ON-surround responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize retinal encoder\n",
    "encoder = RetinalEncoder(resolution=(32, 32))\n",
    "\n",
    "# Encode the image\n",
    "encoded = encoder.encode(image)\n",
    "\n",
    "# Visualize the encoded representations\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(image, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "im1 = axes[1].imshow(encoded['on_center'], cmap='hot')\n",
    "axes[1].set_title('ON-Center Response')\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(im1, ax=axes[1], fraction=0.046)\n",
    "\n",
    "im2 = axes[2].imshow(encoded['off_center'], cmap='hot')\n",
    "axes[2].set_title('OFF-Center Response')\n",
    "axes[2].axis('off')\n",
    "plt.colorbar(im2, ax=axes[2], fraction=0.046)\n",
    "\n",
    "plt.suptitle('Retinal Encoding', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"ON-center shape: {encoded['on_center'].shape}\")\n",
    "print(f\"OFF-center shape: {encoded['off_center'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Convert to Spike Trains\n",
    "\n",
    "Convert the encoded image intensities to spike trains using rate encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize rate encoder\n",
    "rate_encoder = RateEncoder(max_rate=100.0)  # 100 Hz max firing rate\n",
    "\n",
    "# Normalize images to 0-1 range\n",
    "on_normalized = encoded['on_center'] / 255.0\n",
    "off_normalized = encoded['off_center'] / 255.0\n",
    "\n",
    "# Generate spike trains for 100ms simulation\n",
    "duration = 100.0  # ms\n",
    "on_spikes = rate_encoder.encode_array(on_normalized, duration=duration)\n",
    "off_spikes = rate_encoder.encode_array(off_normalized, duration=duration)\n",
    "\n",
    "print(f\"Generated {len(on_spikes)} ON-channel spikes\")\n",
    "print(f\"Generated {len(off_spikes)} OFF-channel spikes\")\n",
    "\n",
    "# Visualize spike statistics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# ON channel spikes\n",
    "on_neurons = [spike[0] for spike in on_spikes]\n",
    "on_times = [spike[1] for spike in on_spikes]\n",
    "\n",
    "axes[0].scatter(on_times[:500], on_neurons[:500], s=1, alpha=0.5)\n",
    "axes[0].set_xlabel('Time (ms)')\n",
    "axes[0].set_ylabel('Neuron ID')\n",
    "axes[0].set_title(f'ON Channel Spikes (first 500/{len(on_spikes)})')\n",
    "axes[0].set_xlim(0, duration)\n",
    "\n",
    "# OFF channel spikes\n",
    "off_neurons = [spike[0] for spike in off_spikes]\n",
    "off_times = [spike[1] for spike in off_spikes]\n",
    "\n",
    "axes[1].scatter(off_times[:500], off_neurons[:500], s=1, alpha=0.5)\n",
    "axes[1].set_xlabel('Time (ms)')\n",
    "axes[1].set_ylabel('Neuron ID')\n",
    "axes[1].set_title(f'OFF Channel Spikes (first 500/{len(off_spikes)})')\n",
    "axes[1].set_xlim(0, duration)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build Visual Processing Network\n",
    "\n",
    "Create a hierarchical network inspired by the visual cortex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the network\n",
    "builder = NetworkBuilder()\n",
    "\n",
    "# Add layers\n",
    "builder.add_sensory_layer(\"retinal\", size=1024)  # 32x32 input\n",
    "builder.add_processing_layer(\"V1\", size=256, neuron_type=\"lif\")\n",
    "builder.add_processing_layer(\"V2\", size=64, neuron_type=\"adex\")\n",
    "builder.add_motor_layer(\"output\", size=10)\n",
    "\n",
    "# Connect layers\n",
    "builder.connect_layers(\"retinal\", \"V1\", \n",
    "                      connection_type=\"feedforward\",\n",
    "                      synapse_type=\"stdp\",\n",
    "                      connection_probability=0.1)\n",
    "\n",
    "builder.connect_layers(\"V1\", \"V2\",\n",
    "                      connection_type=\"feedforward\", \n",
    "                      synapse_type=\"stdp\",\n",
    "                      connection_probability=0.2)\n",
    "\n",
    "builder.connect_layers(\"V2\", \"output\",\n",
    "                      connection_type=\"feedforward\",\n",
    "                      synapse_type=\"stdp\",\n",
    "                      connection_probability=0.3)\n",
    "\n",
    "# Add lateral inhibition in V1\n",
    "builder.connect_layers(\"V1\", \"V1\",\n",
    "                      connection_type=\"lateral\",\n",
    "                      synapse_type=\"stp\",\n",
    "                      connection_probability=0.05)\n",
    "\n",
    "# Build the network\n",
    "network = builder.build()\n",
    "\n",
    "# Display network info\n",
    "info = network.get_network_info()\n",
    "print(\"Network Architecture:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total neurons: {info['total_neurons']}\")\n",
    "print(f\"Total synapses: {info['total_synapses']}\")\n",
    "print(\"\\nLayers:\")\n",
    "for name, layer_info in info['layers'].items():\n",
    "    print(f\"  {name}: {layer_info['size']} neurons ({layer_info['neuron_type']})\")\n",
    "print(\"\\nConnections:\")\n",
    "for conn_name, conn_info in info['connections'].items():\n",
    "    print(f\"  {conn_name}: {conn_info['synapse_type']} (p={conn_info['connection_probability']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run Network Simulation\n",
    "\n",
    "Process the encoded image through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation\n",
    "print(\"Running network simulation...\")\n",
    "results = network.run_simulation(duration=duration, dt=0.1)\n",
    "\n",
    "print(f\"\\nSimulation completed: {results['final_time']} ms\")\n",
    "\n",
    "# Analyze spike activity\n",
    "spike_counts = {}\n",
    "for layer_name, spike_times in results['layer_spike_times'].items():\n",
    "    total_spikes = sum(len(times) for times in spike_times)\n",
    "    spike_counts[layer_name] = total_spikes\n",
    "    avg_rate = (total_spikes / len(spike_times)) / (duration / 1000.0) if len(spike_times) > 0 else 0\n",
    "    print(f\"{layer_name}: {total_spikes} spikes, avg rate: {avg_rate:.1f} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Network Activity\n",
    "\n",
    "Create raster plots and analyze the network's response to the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Original and encoded images\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.imshow(image, cmap='gray')\n",
    "ax1.set_title('Original Image')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.imshow(encoded['on_center'], cmap='hot')\n",
    "ax2.set_title('ON-Center')\n",
    "ax2.axis('off')\n",
    "\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "ax3.imshow(encoded['off_center'], cmap='hot')\n",
    "ax3.set_title('OFF-Center')\n",
    "ax3.axis('off')\n",
    "\n",
    "# Spike raster plots for each layer\n",
    "layer_names = ['retinal', 'V1', 'V2']\n",
    "for idx, layer_name in enumerate(layer_names):\n",
    "    ax = fig.add_subplot(gs[1, idx])\n",
    "    \n",
    "    if layer_name in results['layer_spike_times']:\n",
    "        spike_times = results['layer_spike_times'][layer_name]\n",
    "        \n",
    "        # Plot first N neurons\n",
    "        n_neurons_to_plot = min(50, len(spike_times))\n",
    "        for neuron_id in range(n_neurons_to_plot):\n",
    "            times = spike_times[neuron_id]\n",
    "            if times:\n",
    "                ax.scatter(times, [neuron_id] * len(times), s=0.5, c='black')\n",
    "        \n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        ax.set_ylabel('Neuron ID')\n",
    "        ax.set_title(f'{layer_name} Layer')\n",
    "        ax.set_xlim(0, duration)\n",
    "        ax.set_ylim(0, n_neurons_to_plot)\n",
    "\n",
    "# Spike count histogram\n",
    "ax4 = fig.add_subplot(gs[2, 0])\n",
    "layers = list(spike_counts.keys())\n",
    "counts = list(spike_counts.values())\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(layers)))\n",
    "bars = ax4.bar(layers, counts, color=colors)\n",
    "ax4.set_ylabel('Total Spikes')\n",
    "ax4.set_title('Spike Counts by Layer')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, count in zip(bars, counts):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(count)}', ha='center', va='bottom')\n",
    "\n",
    "# Weight matrix visualization (if available)\n",
    "ax5 = fig.add_subplot(gs[2, 1:])\n",
    "weight_data = []\n",
    "labels = []\n",
    "for conn_name, weight_matrix in results['weight_matrices'].items():\n",
    "    if weight_matrix is not None:\n",
    "        weight_data.append(weight_matrix.flatten())\n",
    "        labels.append(conn_name)\n",
    "\n",
    "if weight_data:\n",
    "    ax5.boxplot(weight_data, labels=labels)\n",
    "    ax5.set_ylabel('Weight Value')\n",
    "    ax5.set_title('Weight Distributions')\n",
    "    ax5.tick_params(axis='x', rotation=45)\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Image Processing Through Spiking Neural Network', fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Receptive Fields\n",
    "\n",
    "Analyze what features the network has learned to detect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze weight matrices to understand learned features\n",
    "print(\"Weight Matrix Analysis:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for conn_name, weight_matrix in results['weight_matrices'].items():\n",
    "    if weight_matrix is not None:\n",
    "        print(f\"\\nConnection: {conn_name}\")\n",
    "        print(f\"  Shape: {weight_matrix.shape}\")\n",
    "        print(f\"  Mean weight: {np.mean(weight_matrix):.4f}\")\n",
    "        print(f\"  Std deviation: {np.std(weight_matrix):.4f}\")\n",
    "        print(f\"  Min weight: {np.min(weight_matrix):.4f}\")\n",
    "        print(f\"  Max weight: {np.max(weight_matrix):.4f}\")\n",
    "        print(f\"  Sparsity: {np.mean(weight_matrix == 0):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Experiment: Different Image Patterns\n",
    "\n",
    "Try different input patterns to see how the network responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pattern(pattern_type='vertical'):\n",
    "    \"\"\"Test network response to different patterns.\"\"\"\n",
    "    \n",
    "    # Create pattern\n",
    "    test_image = np.zeros((64, 64), dtype=np.uint8)\n",
    "    \n",
    "    if pattern_type == 'vertical':\n",
    "        test_image[:, 30:34] = 255\n",
    "    elif pattern_type == 'horizontal':\n",
    "        test_image[30:34, :] = 255\n",
    "    elif pattern_type == 'diagonal':\n",
    "        for i in range(64):\n",
    "            if 0 <= i < 64:\n",
    "                test_image[i, i] = 255\n",
    "                if i > 0:\n",
    "                    test_image[i-1, i] = 200\n",
    "                if i < 63:\n",
    "                    test_image[i+1, i] = 200\n",
    "    elif pattern_type == 'random':\n",
    "        test_image = np.random.randint(0, 256, (64, 64), dtype=np.uint8)\n",
    "    \n",
    "    # Encode and process\n",
    "    encoded_test = encoder.encode(test_image)\n",
    "    \n",
    "    # Quick visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    axes[0].imshow(test_image, cmap='gray')\n",
    "    axes[0].set_title(f'{pattern_type.capitalize()} Pattern')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(encoded_test['on_center'], cmap='hot')\n",
    "    axes[1].set_title('ON Response')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(encoded_test['off_center'], cmap='hot')\n",
    "    axes[2].set_title('OFF Response')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return encoded_test\n",
    "\n",
    "# Test different patterns\n",
    "patterns = ['vertical', 'horizontal', 'diagonal', 'random']\n",
    "for pattern in patterns:\n",
    "    print(f\"\\nTesting {pattern} pattern:\")\n",
    "    encoded_test = test_pattern(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Retinal Encoding**: How images are transformed into ON/OFF center-surround responses\n",
    "2. **Rate Coding**: Converting pixel intensities into spike trains\n",
    "3. **Hierarchical Processing**: Building networks inspired by the visual cortex\n",
    "4. **STDP Learning**: How synaptic weights adapt based on spike timing\n",
    "5. **Network Dynamics**: Visualizing how information flows through the network\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try loading real images using PIL or OpenCV\n",
    "- Experiment with different network architectures\n",
    "- Implement feature detectors (edge, corner, etc.)\n",
    "- Add feedback connections for top-down processing\n",
    "- Test with video sequences for temporal processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
