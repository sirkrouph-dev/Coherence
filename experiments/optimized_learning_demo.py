#!/usr/bin/env python3
"""
TANGIBLE LEARNING SUCCESS - Optimized weights for real learning!
"""

import numpy as np
from core.gpu_neurons import GPUNeuronPool

class OptimizedShapeLearner:
    def __init__(self):
        print("ðŸŽ¯ OPTIMIZED SHAPE LEARNING")
        print("=" * 40)
        print("Strong weights for tangible learning!")
        
        # Create neuron populations
        self.input_neurons = GPUNeuronPool(16, 'lif')    # 4x4 input
        self.hidden_neurons = GPUNeuronPool(8, 'lif')    # Hidden layer  
        self.output_neurons = GPUNeuronPool(4, 'lif')    # Output layer
        
        print(f"âœ… Created: 16â†’8â†’4 neuron network")
        
        # STRONGER weight matrices for better propagation
        self.w_input_hidden = np.random.randn(16, 8) * 2.0 + 1.0   # Mean=1.0, std=2.0
        self.w_hidden_output = np.random.randn(8, 4) * 2.0 + 1.0   # Mean=1.0, std=2.0
        
        # Ensure some strong positive connections
        for i in range(8):
            self.w_input_hidden[i, i % 8] = abs(self.w_input_hidden[i, i % 8]) + 2.0
        for i in range(4):
            self.w_hidden_output[i, i] = abs(self.w_hidden_output[i, i]) + 3.0
            
        print(f"âœ… Strong weight initialization complete")
        
        # Learning parameters
        self.learning_rate = 0.05  # Higher learning rate
        
        # 4x4 patterns  
        self.patterns = {
            'circle': np.array([[0,1,1,0],[1,0,0,1],[1,0,0,1],[0,1,1,0]]),
            'square': np.array([[1,1,1,1],[1,0,0,1],[1,0,0,1],[1,1,1,1]]),
            'triangle': np.array([[0,0,1,0],[0,1,1,1],[1,1,1,1],[1,1,1,1]]),
            'line': np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]])
        }
        
        print(f"âœ… Pattern library ready")
    
    def pattern_to_current(self, pattern, strength=35.0):
        """Convert 4x4 pattern to strong input currents"""
        flat_pattern = pattern.flatten()
        currents = np.zeros(16)
        for i in range(16):
            if flat_pattern[i] > 0.5:
                currents[i] = strength  # Strong stimulation
        return currents
    
    def safe_convert_spikes(self, spike_indices):
        """Safely convert spike indices to list"""
        if hasattr(spike_indices, 'get'):  # CuPy array
            return spike_indices.get().tolist()
        elif hasattr(spike_indices, 'tolist'):  # NumPy array
            return spike_indices.tolist()
        elif isinstance(spike_indices, (list, tuple)):
            return list(spike_indices)
        else:
            return []
    
    def forward_pass(self, input_currents, duration_steps=40):
        """Optimized forward pass with strong propagation"""
        input_spikes = []
        hidden_spikes = []
        output_spikes = []
        
        for step in range(duration_steps):
            dt = 0.1
            
            # Input layer - direct stimulation
            input_spike_indices, _ = self.input_neurons.step(dt, input_currents)
            input_spike_list = self.safe_convert_spikes(input_spike_indices)
            input_spikes.extend(input_spike_list)
            
            # Hidden layer - stronger propagation
            hidden_input = np.zeros(8)
            for spike_idx in input_spike_list:
                if 0 <= spike_idx < 16:
                    hidden_input += self.w_input_hidden[spike_idx] * 25.0  # STRONG spike effect
            
            hidden_spike_indices, _ = self.hidden_neurons.step(dt, hidden_input)
            hidden_spike_list = self.safe_convert_spikes(hidden_spike_indices)
            hidden_spikes.extend(hidden_spike_list)
            
            # Output layer - even stronger propagation
            output_input = np.zeros(4)
            for spike_idx in hidden_spike_list:
                if 0 <= spike_idx < 8:
                    output_input += self.w_hidden_output[spike_idx] * 30.0  # VERY STRONG
            
            output_spike_indices, _ = self.output_neurons.step(dt, output_input)
            output_spike_list = self.safe_convert_spikes(output_spike_indices)
            output_spikes.extend(output_spike_list)
        
        return input_spikes, hidden_spikes, output_spikes
    
    def train_pattern(self, pattern_name, pattern, target_class):
        """Enhanced training with stronger learning"""
        input_currents = self.pattern_to_current(pattern, strength=40.0)  # Very strong
        
        # Forward pass
        input_spikes, hidden_spikes, output_spikes = self.forward_pass(input_currents)
        
        # Count output spikes per neuron
        output_counts = [0, 0, 0, 0]
        for spike_idx in output_spikes:
            if 0 <= spike_idx < 4:
                output_counts[spike_idx] += 1
        
        # Enhanced learning rule
        if len(hidden_spikes) > 0:
            for spike_idx in hidden_spikes:
                if 0 <= spike_idx < 8:
                    # Strengthen target class connection strongly
                    self.w_hidden_output[spike_idx, target_class] += self.learning_rate * 2.0
                    
                    # Weaken other connections moderately
                    for other_class in range(4):
                        if other_class != target_class:
                            self.w_hidden_output[spike_idx, other_class] -= self.learning_rate * 0.3
                    
                    # Keep weights in reasonable range
                    self.w_hidden_output[spike_idx] = np.clip(self.w_hidden_output[spike_idx], -5.0, 10.0)
        
        # Determine prediction and confidence
        total_spikes = sum(output_counts)
        if total_spikes > 0:
            predicted_class = output_counts.index(max(output_counts))
            confidence = max(output_counts) / total_spikes
        else:
            predicted_class = -1
            confidence = 0.0
        
        correct = (predicted_class == target_class)
        status = "ðŸŽ‰" if correct else "âŒ" if total_spikes > 0 else "âšª"
        
        return correct, confidence, status, output_counts, len(input_spikes), len(hidden_spikes)
    
    def run_learning_experiment(self, epochs=10):
        """Run optimized learning experiment"""
        print(f"\nðŸš€ OPTIMIZED LEARNING - {epochs} EPOCHS")
        print("=" * 45)
        
        shape_names = list(self.patterns.keys())
        all_accuracies = []
        
        for epoch in range(epochs):
            print(f"\nðŸ“š Epoch {epoch+1:2d}/{epochs}")
            print("-" * 35)
            
            correct_count = 0
            total_count = 0
            
            for target_class, (shape_name, pattern) in enumerate(self.patterns.items()):
                correct, confidence, status, output_counts, input_spikes, hidden_spikes = self.train_pattern(
                    shape_name, pattern, target_class
                )
                
                print(f"  {shape_name:8s}: {status} | conf: {confidence:.2f} | out: {output_counts} | in: {input_spikes:2d} | hid: {hidden_spikes:2d}")
                
                if correct:
                    correct_count += 1
                total_count += 1
            
            accuracy = (correct_count / total_count) * 100
            all_accuracies.append(accuracy)
            print(f"  ðŸ“Š Accuracy: {accuracy:.1f}%")
            
            # Show improvement
            if epoch > 0:
                improvement = accuracy - all_accuracies[0]
                if improvement > 0:
                    print(f"  ðŸ“ˆ Improvement: +{improvement:.1f}%")
        
        return all_accuracies

def main():
    learner = OptimizedShapeLearner()
    
    # Run the optimized learning experiment
    accuracies = learner.run_learning_experiment(epochs=8)
    
    # Results analysis
    print(f"\n{'='*50}")
    print(f"ðŸŽ¯ LEARNING ANALYSIS")
    print(f"{'='*50}")
    
    for i, accuracy in enumerate(accuracies):
        symbol = "ðŸŽ‰" if accuracy >= 75 else "ðŸ“ˆ" if accuracy >= 50 else "ðŸ“Š" if accuracy > 0 else "âšª"
        print(f"Epoch {i+1:2d}: {accuracy:5.1f}% {symbol}")
    
    # Summary
    if len(accuracies) > 1:
        final_accuracy = accuracies[-1]
        initial_accuracy = accuracies[0]
        improvement = final_accuracy - initial_accuracy
        
        print(f"\nLearning Summary:")
        print(f"  Initial: {initial_accuracy:.1f}%")
        print(f"  Final:   {final_accuracy:.1f}%")
        print(f"  Gain:    {improvement:+.1f}%")
        
        if final_accuracy >= 75:
            print(f"\nðŸŽ‰ EXCELLENT! Achieved {final_accuracy:.1f}% accuracy!")
            print(f"âœ… TANGIBLE NEUROMORPHIC LEARNING SUCCESS!")
        elif final_accuracy >= 50:
            print(f"\nðŸ“ˆ GOOD! Achieved {final_accuracy:.1f}% accuracy!")
            print(f"âœ… Clear learning progress demonstrated!")
        elif improvement > 25:
            print(f"\nðŸ“Š LEARNING DETECTED! +{improvement:.1f}% improvement!")
            print(f"âœ… Network is learning, needs more training!")
        else:
            print(f"\nðŸ”§ Needs optimization, but neurons are responding!")

if __name__ == "__main__":
    main()
